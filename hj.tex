\chapter{Hash Join}
\label{hj}

Hash Join is another workhorse operator in database systems used most frequently among all join operators. There are many variants of Hash Join - Simple, Grace, Hybrid and many more. In all the variants, a hash table is built on the inner relation tuples and outer tuples are used to probe matching value for join columns on that table. Assuming $R$ as the outer relation and $S$ as inner relation, we will be using $|R|$ and $|S|$ to denote the number of tuples in the outer and the inner relations respectively.

In the general case, when we build a Hash Table on the inner Relation, we put 2 fields for each tuple at the minimum. These are (a) a pointer to the tuple and (b) the Hash Value of the join column(s)

Assuming write/read ratio is $\lambda$. If we skip writing the Hash Value field, we would need to read the tuple each time from PCM. The slowdown that would happen then would be : $\lambda \times numentries$ in a bucket. Assuming each of the buckets is greater than DRAM capacity, the tuple width is greater than DRAM block , and there is no prefetching, the number of reads would then be $\lambda \times numentries in a bucket \times |R| + \lambda \times |S|$ . 

That being the approach that creates least number of writes, we may want to trade-off some reads for writes and reduce the time for join. In principle, we can sort individual buckets in both the inner and the outer relations and then go about joining them. Clearly, we do not visit the same entry again in a bucket once the join column value crosses the value of the entry, similar to the case of merge join. Hence, the time taken for such an approach will be approximately $\lambda \times numOuter tuples + \lambda \times Num_Inner_Tuples$ under the same assumptions as previous. For sorting, we could use positional index to avoid the writes due to shuffling entire tuples

A third approach takes the middle ground between cycles and writes. If we associate with each tuple pointer a 1 byte hash value, it will prevent fetching each inner relation tuple's join column value for each probe of outer relation. Assuming inner relation tuples are uniformly distributed and the hash function maintains this uniformity in hash values also, the chances of collision of hash values would be  $numtuples in a bucket/2^8 = numTuples/256 $. Then the number of PCM accesses required would be $numTuplesinBucket/256$. This approach was used by \cite{abhimanyu}

We suggest an optimization on the top of the last approach. We term the new algorithm as Multi-Pass Hash Join. In this approach, we pass through all the $|R|$ and $|S|$ tuples multiple times over multiple iterations. In each iteration, we hash a DRAM sized subset of $|S|$ tuples and join them with matching $R$ tuples. The thing to note here is that we don't perform any partitioning phase since partitioning will incur extra writes. Instead, we make multiple read passes through the tuples of both the relations.